{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "hHhEg22DHPdk"
   },
   "source": [
    "# Trajectory 사람 이동 예측\n",
    "trajectory 데이터에서 총 180명 정도의 데이터가 존재 <br>\n",
    "개인 별로 어떻게 움직일지를 lstm, gru (파라미터가 좀 작을 때 사용하는 모델),transfomer 모형을 활용해서 학습해볼 예정 <br>\n",
    "## 표본 선정 기준<br>\n",
    "1. 수집 일 수가 많을 것 <br>\n",
    "2. 일정하게 데이터가 존재할 것 <br>\n",
    "결과적으로 총 6명을 학습 할 예정이다. <br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "w2by2nymIgSU",
    "outputId": "011334a3-4767-476d-b125-bb61193d82be"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mounted at /content/drive\n"
     ]
    }
   ],
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ga6JVClMIjLO",
    "outputId": "1cffb431-9b59-4236-ca1e-a7dc9110df64"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/content/drive\n"
     ]
    }
   ],
   "source": [
    "cd drive"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "b3UPoLuYIld1",
    "outputId": "9ce9c363-d94d-4cc9-c247-d771ed459176"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/content/drive/MyDrive\n"
     ]
    }
   ],
   "source": [
    "cd MyDrive"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "fjTYwmYCIn-c",
    "outputId": "2ed49631-9d3a-45d3-9efd-8916570c76fa"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/content/drive/MyDrive/DeepLearning_14Team\n"
     ]
    }
   ],
   "source": [
    "cd DeepLearning_14Team/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "gH2pGAmeHPdr"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "list_ = os.listdir('sorted_data/128/Trajectory/')\n",
    "sorted_41 = []\n",
    "for i in range(len(list_)):\n",
    "    file_ = open('sorted_data/128/Trajectory/' + list_[i], 'r') \n",
    "    file = file_.readlines()\n",
    "    file = file[6:]\n",
    "    for j in range(len(file)):\n",
    "        tmp = file[j].split(',')\n",
    "        sorted_41.append([float(tmp[0]), float(tmp[1]), tmp[-2] + ' ' +tmp[-1][:-1]])\n",
    "\n",
    "df = pd.DataFrame(sorted_41)\n",
    "df[2] = pd.to_datetime(df[2])\n",
    "df.sort_values(by = [2],inplace=True)\n",
    "df = df.reset_index()\n",
    "df = df[[0,1,2]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Q3ym8KKtHPds",
    "outputId": "c2824bba-81ca-457a-d724-081b5723b73b"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1208500"
      ]
     },
     "execution_count": 41,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 41,
     "resources": {
      "http://localhost:8080/nbextensions/google.colab/files.js": {
       "data": "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",
       "headers": [
        [
         "content-type",
         "application/javascript"
        ]
       ],
       "ok": true,
       "status": 200,
       "status_text": ""
      }
     }
    },
    "id": "u51x-5-wvK-S",
    "outputId": "1ec5e76d-3b49-49c2-9203-865ea281a650"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "     <input type=\"file\" id=\"files-70381aae-dd90-4438-94f9-e221f1496aa9\" name=\"files[]\" multiple disabled\n",
       "        style=\"border:none\" />\n",
       "     <output id=\"result-70381aae-dd90-4438-94f9-e221f1496aa9\">\n",
       "      Upload widget is only available when the cell has been executed in the\n",
       "      current browser session. Please rerun this cell to enable.\n",
       "      </output>\n",
       "      <script src=\"/nbextensions/google.colab/files.js\"></script> "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {
      "tags": []
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "from google.colab import files\n",
    "\n",
    "uploaded = files.upload()\n",
    "\n",
    "for fn in uploaded.keys():\n",
    "  print('User uploaded file \"{name}\" with length {length} bytes'.format(\n",
    "      name=fn, length=len(uploaded[fn])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "hVM8NAmQvLcy"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "df = pd.read_csv('sorted_128_last_1000.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Jt5H5hRtHPdt"
   },
   "source": [
    "# 데이터 분리하기\n",
    "1. 데이터가 너무 많다는 점\n",
    "2. 어느 곳에 방문할지에 대한 정보가 좀 더 중요하다는 점\n",
    "3. 사람이 걸을 수 있는 정도가 한정되어 있다는 점 <br>\n",
    "세가지를 고려할 때 모두를 학습시키기 보다는 일부분을 쪼개서 학습시키는 것이 합리적"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "uYIu6StpHPdv",
    "outputId": "4e2d8a5d-d358-4ece-c5db-60e4426e45c5"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Timedelta('0 days 00:01:27.645094826')"
      ]
     },
     "execution_count": 9,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result / len(a)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "zgw6CorrHPdv"
   },
   "source": [
    "# 30분 단위로 쪼개서 이 사람의 미래 예측하는 형태\n",
    "    평균이 1분 27초 정도되니 30정도 곱해서 30분 단위로 예측해볼 것임\n",
    "\n",
    "train, test, val set으로 분리하였다. <br>\n",
    "시간이 중요한게 아니라 순서가 중요하다고 할 수 있는건가? <br>\n",
    "균일하게 되어 있는가?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "DsKqvFtxHPdv"
   },
   "outputs": [],
   "source": [
    "df_diff_30_train = []\n",
    "for i in range(0,len(df),30):\n",
    "    df_diff_30_train.append(df.iloc[i])\n",
    "df_diff_30_val = []\n",
    "for i in range(10, len(df), 30):\n",
    "    df_diff_30_val.append(df.iloc[i])\n",
    "df_diff_30_test = []\n",
    "for i in range(20, len(df), 30):\n",
    "    df_diff_30_test.append(df.iloc[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "wP1EIJFsHPdw",
    "outputId": "8d6306df-981c-4eb7-8596-eceb2420f0dc"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "37028"
      ]
     },
     "execution_count": 9,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(df_diff_30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "sEWJ1I59HPdw"
   },
   "outputs": [],
   "source": [
    "df_diff_30_train_pd = pd.DataFrame(df_diff_30_train)\n",
    "df_diff_30_test_pd = pd.DataFrame(df_diff_30_test)\n",
    "df_diff_30_val_pd = pd.DataFrame(df_diff_30_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "SVc6JmRq8ULQ"
   },
   "outputs": [],
   "source": [
    "x, y = df_diff_30_train_pd['0'], df_diff_30_train_pd['1']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "BNsf2y-mHPdw",
    "outputId": "6c6e709f-6027-4aa5-adb0-d44b65ce3188"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0      116.327817\n",
       "30     116.321833\n",
       "60     116.323883\n",
       "90     116.320683\n",
       "120    116.325833\n",
       "150    116.310317\n",
       "180    116.311717\n",
       "210    116.309617\n",
       "240    116.309717\n",
       "270    116.313667\n",
       "300    116.322567\n",
       "330    116.328100\n",
       "360    116.329650\n",
       "390    116.327583\n",
       "420    116.321033\n",
       "450    116.322983\n",
       "480    116.297283\n",
       "510    116.282217\n",
       "540    116.262100\n",
       "570    116.243333\n",
       "600    116.232183\n",
       "630    116.222750\n",
       "660    116.250917\n",
       "690    116.262900\n",
       "720    116.268900\n",
       "750    116.262883\n",
       "780    116.294067\n",
       "810    116.304850\n",
       "840    116.301350\n",
       "870    116.307233\n",
       "900    116.310017\n",
       "930    116.301583\n",
       "960    116.291483\n",
       "990    116.297633\n",
       "Name: 1, dtype: float64"
      ]
     },
     "execution_count": 15,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "HPu6dCeeHPdw"
   },
   "source": [
    "# 30분 단위로 쪼갠다!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ZGuHfZXfHPdx"
   },
   "outputs": [],
   "source": [
    "df_128_30 = pd.DataFrame(df_diff_30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "id": "Wky0QtsXHPdx"
   },
   "outputs": [],
   "source": [
    "train_x, train_y = df_diff_30_train_pd[0], df_diff_30_train_pd[1]\n",
    "test_x, test_y = df_diff_30_test_pd[0], df_diff_30_test_pd[1]\n",
    "val_x, val_y = df_diff_30_val_pd[0], df_diff_30_val_pd[1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "9_qBlKkvHPdx"
   },
   "source": [
    "# 모델 학습 데이터 준비\n",
    "    x, y 차원을 맞추는 것이 어려운 점이었음\n",
    "    lstm 모델 2개를 활용해서 한 차원 당 1개의 모델을 사용하도록 하였음.\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "o77qrORI_q8z",
    "outputId": "a45af337-7078-4a32-ce3f-e5f871130d18"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0      40.075850\n",
       "1      40.075833\n",
       "2      40.076000\n",
       "3      40.076300\n",
       "4      40.076600\n",
       "         ...    \n",
       "995    40.255033\n",
       "996    40.255067\n",
       "997    40.255217\n",
       "998    40.255483\n",
       "999    40.255733\n",
       "Name: 0, Length: 1000, dtype: float64"
      ]
     },
     "execution_count": 28,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "id": "nyhj4QsnHPdx"
   },
   "outputs": [],
   "source": [
    "import random\n",
    "import numpy as np\n",
    "import torch\n",
    "\n",
    "# multivariate data preparation\n",
    "from numpy import array\n",
    "from numpy import hstack\n",
    " \n",
    "# split a multivariate sequence into samples\n",
    "def split_sequences(sequences, n_steps):\n",
    "    X, y = list(), list()\n",
    "    for i in range(len(sequences) - n_steps):\n",
    "        # find the end of this pattern\n",
    "        end_ix = i + n_steps\n",
    "        # check if we are beyond the dataset\n",
    "        if end_ix > len(sequences):\n",
    "            break\n",
    "        # gather input and output parts of the pattern\n",
    "        seq_x, seq_y = sequences[i:end_ix, :-2], sequences[end_ix, -2:]\n",
    "        X.append(seq_x)\n",
    "        y.append(seq_y)\n",
    "    return array(X), array(y)\n",
    " \n",
    "# train x, y\n",
    "# define input sequence\n",
    "in_seq1 = train_x.values\n",
    "in_seq2 = train_y.values\n",
    "#out_seq = np.array([in_seq1[i]+in_seq2[i] for i in range(len(in_seq1))])\n",
    "# convert to [rows, columns] structure\n",
    "in_seq1 = in_seq1.reshape((len(in_seq1), 1))\n",
    "in_seq2 = in_seq2.reshape((len(in_seq2), 1))\n",
    "#out_seq = out_seq.reshape((len(out_seq), 1))\n",
    "# horizontally stack columns\n",
    "train_dataset = hstack((in_seq1, in_seq2, in_seq1, in_seq2))\n",
    "\n",
    "# test x, y\n",
    "# define input sequence\n",
    "in_seq1 = train_x.values\n",
    "in_seq2 = train_y.values\n",
    "#out_seq = np.array([in_seq1[i]+in_seq2[i] for i in range(len(in_seq1))])\n",
    "# convert to [rows, columns] structure\n",
    "in_seq1 = in_seq1.reshape((len(in_seq1), 1))\n",
    "in_seq2 = in_seq2.reshape((len(in_seq2), 1))\n",
    "#out_seq = out_seq.reshape((len(out_seq), 1))\n",
    "# horizontally stack columns\n",
    "test_dataset = hstack((in_seq1, in_seq2, in_seq1, in_seq2))\n",
    "\n",
    "# val x, y\n",
    "# define input sequence\n",
    "in_seq1 = train_x.values\n",
    "in_seq2 = train_y.values\n",
    "#out_seq = np.array([in_seq1[i]+in_seq2[i] for i in range(len(in_seq1))])\n",
    "# convert to [rows, columns] structure\n",
    "in_seq1 = in_seq1.reshape((len(in_seq1), 1))\n",
    "in_seq2 = in_seq2.reshape((len(in_seq2), 1))\n",
    "#out_seq = out_seq.reshape((len(out_seq), 1))\n",
    "# horizontally stack columns\n",
    "val_dataset = hstack((in_seq1, in_seq2, in_seq1, in_seq2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "id": "xtp9J4geHPdy"
   },
   "outputs": [],
   "source": [
    "df_train_x, df_train_y  = split_sequences(train_dataset, 5)\n",
    "df_test_x, df_test_y = split_sequences(test_dataset, 5)\n",
    "df_val_x, df_val_y = split_sequences(val_dataset, 5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "bWJ4rr3EHPdy"
   },
   "source": [
    "# lstm 모델 학습"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "id": "uSZ_WYjHOBaw"
   },
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "id": "dKNaodryXRbc"
   },
   "outputs": [],
   "source": [
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "id": "vIa1PMEBHPdy"
   },
   "outputs": [],
   "source": [
    "class MV_LSTM(torch.nn.Module):\n",
    "    def __init__(self,n_features,seq_length):\n",
    "        super(MV_LSTM, self).__init__()\n",
    "        self.n_features = n_features\n",
    "        self.seq_len = seq_length\n",
    "        self.n_hidden = 100 # number of hidden states\n",
    "        self.n_layers = 300 # number of LSTM layers (stacked)\n",
    "    \n",
    "        self.l_lstm = torch.nn.LSTM(input_size = n_features, \n",
    "                                 hidden_size = self.n_hidden,\n",
    "                                 num_layers = self.n_layers, \n",
    "                                batch_first = True,dropout=0.1).to(device)\n",
    "        # according to pytorch docs LSTM output is \n",
    "        # (batch_size,seq_len, num_directions * hidden_size)\n",
    "        # when considering batch_first = True\n",
    "        self.l_linear = torch.nn.Linear(self.n_hidden*self.seq_len, 1).to(device)\n",
    "        self.relu = torch.nn.ReLU()\n",
    "        \n",
    "    \n",
    "    def init_hidden(self, batch_size):\n",
    "        # even with batch_first = True this remains same as docs\n",
    "        hidden_state = torch.zeros(self.n_layers,batch_size, self.n_hidden, device= device)\n",
    "        cell_state = torch.zeros(self.n_layers,batch_size, self.n_hidden, device = device)\n",
    "        self.hidden = (hidden_state, cell_state)\n",
    "    \n",
    "    \n",
    "    def forward(self, x):\n",
    "        batch_size, seq_len, _ = x.size()\n",
    "        \n",
    "        lstm_out, self.hidden = self.l_lstm(x, self.hidden)\n",
    "        lstm_out = self.relu(lstm_out)\n",
    "        # lstm_out(with batch_first = True) is \n",
    "        # (batch_size,seq_len,num_directions * hidden_size)\n",
    "        # for following linear layer we want to keep batch_size dimension and merge rest       \n",
    "        # .contiguous() -> solves tensor compatibility error\n",
    "        x = lstm_out.contiguous().view(batch_size,-1)\n",
    "        return self.l_linear(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "id": "RhCBQdExHPdz"
   },
   "outputs": [],
   "source": [
    "n_features = 1 # this is number of parallel inputs\n",
    "n_timesteps = 5 # this is number of timesteps\n",
    "\n",
    "# convert dataset into input/output\n",
    "df_train = split_sequences(train_dataset, 5)\n",
    "df_test = split_sequences(test_dataset, 5)\n",
    "df_val = split_sequences(val_dataset, 5)\n",
    "\n",
    "# create NN\n",
    "mv_net_x = MV_LSTM(n_features, n_timesteps)\n",
    "mv_net_y = MV_LSTM(n_features, n_timesteps)\n",
    "criterion = torch.nn.MSELoss().to(device=device)\n",
    " # reduction='sum' created huge loss value\n",
    "optimizer_x = torch.optim.Adam(mv_net_x.parameters(), lr=1e-1)\n",
    "optimizer_y = torch.optim.Adam(mv_net_y.parameters(), lr=1e-1)\n",
    "\n",
    "# scheduler\n",
    "scheduler_x = torch.optim.lr_scheduler.StepLR(optimizer_x, 1.0, gamma=0.95)\n",
    "scheduler_y = torch.optim.lr_scheduler.StepLR(optimizer_y, 1.0, gamma=0.95)\n",
    "\n",
    "# MV_LSTM(n_features, n_timesteps) # n_hidden, n_layers\n",
    "mv_net_test = MV_LSTM(n_features, n_timesteps)\n",
    "layer = mv_net_test.n_layers\n",
    "hidden = mv_net_test.n_hidden\n",
    "\n",
    "train_episodes = 30\n",
    "batch_size = 50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "G6Y0pnrIHPdz",
    "outputId": "39a69682-75dc-45ad-e5da-90e0b481585a"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "numpy.ndarray"
      ]
     },
     "execution_count": 21,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(X) \n",
    "# 여기서 타입 에러가 발생했음 # float 타입으로 결과를 만들어야 했는데\n",
    "# 위에서 string 타입으로 데이터 프레임을 만들어내서 문제가 발생"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "UlJ5BybsHPd0"
   },
   "source": [
    "# 여기서도 어려웠던 점\n",
    "    인풋 사이즈를 맞춰줘야 하는데 그 자체가 코드를 모두 이해하여야 했기에 엄청난 어려움이 있었다.\n",
    "    ★시계열 데이터이기 때문에 마지막 배치의 경우에 문제가 존재했음 -> 이 부분을 처리하는 것이 중요!\n",
    "    텐서 자체에서 문제가 존재했고, 데이터를 텐서로 변환하는 과정에서 소수점의 사라짐이 존재하게 되었음 이러한 문제점을 해결하는 방법은?\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "P166XhLC_pEz"
   },
   "outputs": [],
   "source": [
    "처음에 트레인, 테스트, 벨리데이션 셋을 나누지 않고 모델을 만들었다.\n",
    "그러나 이후에 이 모델이 잘 만들어 졌는지를 확인하기 위해서 찾아보니 다음과 같은 방식으로 처리한다는 것을 알게 되었다.\n",
    "이후에 코드를 수정하여 메트릭을 평가할 수 있었다.\n",
    "그리고 10분, 20분, 30분 부터 시작하여 30분씩 미래 데이터를 예측해보고자 하였음"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "id": "9qVnGi52GdI5"
   },
   "outputs": [],
   "source": [
    "torch.set_printoptions(precision=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "id": "J8NQJdXDHPd1"
   },
   "outputs": [],
   "source": [
    "def train():\n",
    "    mv_net_x.train()\n",
    "    mv_net_y.train()\n",
    "    start_time = time.time()\n",
    "    total_loss = 0.\n",
    "\n",
    "    for b in range(0,len(df_train_x),batch_size):\n",
    "        inpt = df_train_x[b:b+batch_size,:,:]\n",
    "        target = df_train_y[b:b+batch_size]\n",
    "\n",
    "        # x, y 트레인셋\n",
    "        x_batch = torch.tensor(inpt[:,:,0],dtype=torch.float32, device = device) # 텐서로 바꾸면서\n",
    "        y_batch = torch.tensor(inpt[:,:,1],dtype=torch.float32, device = device)\n",
    "        \n",
    "        if x_batch.shape == (batch_size,n_timesteps):\n",
    "            x_batch = x_batch.reshape(batch_size,n_timesteps,1) # 3 채널로 맞춰줘야 함\n",
    "            y_batch = y_batch.reshape(batch_size,n_timesteps,1)\n",
    "\n",
    "            mv_net_x.init_hidden(x_batch.size(0))\n",
    "            mv_net_y.init_hidden(y_batch.size(0))\n",
    "\n",
    "            # x,y의 예측 값\n",
    "            output_x = mv_net_x(x_batch)\n",
    "            output_y = mv_net_y(y_batch)\n",
    "\n",
    "            # x,y의 정답\n",
    "            target_x_batch = torch.tensor(target[:, 0],dtype=torch.float32, device = device)\n",
    "            target_y_batch = torch.tensor(target[:, 1],dtype=torch.float32, device = device)\n",
    "\n",
    "\n",
    "        #    lstm_out, _ = mv_net.l_lstm(x_batch,nnet.hidden)    \n",
    "        #    lstm_out.contiguous().view(x_batch.size(0),-1)\n",
    "\n",
    "            # loss function이 두개의 합이 최소가 되는 쪽으로 loss를 구함\n",
    "            loss = criterion(output_x.view(-1), target_x_batch) + criterion(output_y.view(-1), target_y_batch)\n",
    "            loss.backward()\n",
    "\n",
    "            optimizer_x.step()        \n",
    "            optimizer_x.zero_grad() # x가 0으로 흐르도록 함\n",
    "\n",
    "            optimizer_y.step()\n",
    "            optimizer_y.zero_grad() # y가 0으로 흐르도록 함\n",
    "\n",
    "            total_loss += loss.item()\n",
    "\n",
    "            elapsed = time.time() - start_time\n",
    "            # print('| epoch {:3d} | {:5d}/{:5d} batches | '\n",
    "            # 'lr {:02.2f} |'\n",
    "            # 'loss {:5.2f}'.format(t, b, len(train_x) / batch_size, scheduler_x.get_lr()[0], total_loss))\n",
    "\n",
    "#        print('step : ' , t , 'loss : ' , loss.item())\n",
    "\n",
    "def evaluate(eval_x_model, eval_y_model):\n",
    "    eval_x_model.eval() # Turn on the evaluation mode\n",
    "    eval_y_model.eval()\n",
    "\n",
    "    total_loss = 0.\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for b in range(0,len(df_train_x),batch_size):\n",
    "            inpt = df_train_x[b:b+batch_size,:,:]\n",
    "            target = df_train_y[b:b+batch_size]\n",
    "\n",
    "            # x, y 트레인셋\n",
    "            x_batch = torch.tensor(inpt[:,:,0],dtype=torch.float32, device = device) # 텐서로 바꾸면서\n",
    "            y_batch = torch.tensor(inpt[:,:,1],dtype=torch.float32, device = device)\n",
    "            \n",
    "            if x_batch.shape == (batch_size,n_timesteps):\n",
    "                x_batch = x_batch.reshape(batch_size,n_timesteps,1) # 3 채널로 맞춰줘야 함\n",
    "                y_batch = y_batch.reshape(batch_size,n_timesteps,1)\n",
    "\n",
    "                eval_x_model.init_hidden(x_batch.size(0))\n",
    "                eval_y_model.init_hidden(y_batch.size(0))\n",
    "\n",
    "                # x,y의 예측 값\n",
    "                output_x = eval_x_model(x_batch)\n",
    "                output_y = eval_y_model(y_batch)\n",
    "\n",
    "                # x,y의 정답\n",
    "                target_x_batch = torch.tensor(target[:, 0],dtype=torch.float32, device = device)\n",
    "                target_y_batch = torch.tensor(target[:, 1],dtype=torch.float32, device = device)\n",
    "\n",
    "\n",
    "                total_loss += criterion(output_x.view(-1), target_x_batch).item() + criterion(output_y.view(-1), target_y_batch).item()\n",
    "\n",
    "    return total_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Qa3wKoi8yaq8",
    "outputId": "e8bdfa5b-62a3-40de-992a-63db6fb2912e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mounted at /content/drive\n"
     ]
    }
   ],
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "jxs_nTchyiXM",
    "outputId": "50c27e69-fccb-434c-9d46-e9ad150ec62d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/content/drive\n"
     ]
    }
   ],
   "source": [
    "cd drive"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "j4FiwROyyr4t",
    "outputId": "aecca115-587f-4b48-e094-a848477abdfe"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/content/drive/MyDrive\n"
     ]
    }
   ],
   "source": [
    "cd MyDrive"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "MtCmUIv2yujM",
    "outputId": "98056e6b-e28e-4a66-b426-bd243de24b8d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/content/drive/My Drive/DeepLearning_14Team\n"
     ]
    }
   ],
   "source": [
    "cd DeepLearning_14Team"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "wr8P2G2jQSm-"
   },
   "outputs": [],
   "source": [
    "import time\n",
    "\n",
    "best_val_loss = float(\"inf\")\n",
    "epochs = 10 # The number of epochs\n",
    "best_model = None\n",
    "\n",
    "for epoch in range(1, epochs + 1):\n",
    "    epoch_start_time = time.time()\n",
    "    train()\n",
    "    val_loss = evaluate(mv_net_x, mv_net_y)\n",
    "    print('-' * 89)\n",
    "    print('| end of epoch {:3d} | time: {:5.2f}s | valid loss {:5.2f}'.format(epoch, (time.time() - epoch_start_time), val_loss))\n",
    "    print('-' * 89)\n",
    "\n",
    "    if val_loss < best_val_loss:\n",
    "        best_val_loss = val_loss\n",
    "        best_model_x = mv_net_x\n",
    "        best_model_y = mv_net_y\n",
    "\n",
    "        PATH_x = \"lstm_checkpoint/LSTM + MSE x episode : {}, batch_size : {}, layer : {}, hidden : {}, epoch : {}\".format(epoch,batch_size,layer,hidden, epoch) + \".pt\"\n",
    "        torch.save({\n",
    "        'epoch': epoch,\n",
    "        'model_state_dict': mv_net_x.state_dict(),\n",
    "        'optimizer_state_dict': optimizer_x.state_dict(),\n",
    "        'loss': best_val_loss,\n",
    "        }, PATH_x)\n",
    "\n",
    "        PATH_y = \"lstm_checkpoint/LSTM + MSE y episode : {}, batch_size : {}, layer : {}, hidden : {}, epoch : {}\".format(epoch,batch_size,layer,hidden, epoch) + \".pt\"\n",
    "        torch.save({\n",
    "        'epoch': epoch,\n",
    "        'model_state_dict': mv_net_y.state_dict(),\n",
    "        'optimizer_state_dict': optimizer_x.state_dict(),\n",
    "        'loss': best_val_loss,\n",
    "        }, PATH_y)\n",
    "\n",
    "    scheduler_x.step()\n",
    "    scheduler_y.step()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "7Redl8BB7F7l"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "rkGdUHkaH4gx"
   },
   "outputs": [],
   "source": [
    "criterion = nn.CrossEntropyLoss()\n",
    "lr = 5.0 # learning rate\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=lr)\n",
    "scheduler = torch.optim.lr_scheduler.StepLR(optimizer, 1.0, gamma=0.95)\n",
    "\n",
    "import time\n",
    "def train():\n",
    "    model.train() # Turn on the train mode\n",
    "    total_loss = 0.\n",
    "    start_time = time.time()\n",
    "    ntokens = len(TEXT.vocab.stoi)\n",
    "    for batch, i in enumerate(range(0, train_data.size(0) - 1, bptt)):\n",
    "        data, targets = get_batch(train_data, i)\n",
    "        optimizer.zero_grad()\n",
    "        output = model(data)\n",
    "        loss = criterion(output.view(-1, ntokens), targets)\n",
    "        loss.backward()\n",
    "        torch.nn.utils.clip_grad_norm_(model.parameters(), 0.5)\n",
    "        optimizer.step()\n",
    "\n",
    "        total_loss += loss.item()\n",
    "        log_interval = 200\n",
    "        if batch % log_interval == 0 and batch > 0:\n",
    "            cur_loss = total_loss / log_interval\n",
    "            elapsed = time.time() - start_time\n",
    "            print('| epoch {:3d} | {:5d}/{:5d} batches | '\n",
    "                  'lr {:02.2f} | ms/batch {:5.2f} | '\n",
    "                  'loss {:5.2f} | ppl {:8.2f}'.format(\n",
    "                    epoch, batch, len(train_data), scheduler.get_lr()[0],\n",
    "                    elapsed * 1000 / log_interval,\n",
    "                    cur_loss, math.exp(cur_loss)))\n",
    "            total_loss = 0\n",
    "            start_time = time.time()\n",
    "\n",
    "def evaluate(eval_model, data_source):\n",
    "    eval_model.eval() # Turn on the evaluation mode\n",
    "    total_loss = 0.\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for i in range(0, data_source.size(0) - 1, bptt):\n",
    "            data, targets = get_batch(data_source, i)\n",
    "            output = eval_model(data)\n",
    "            output_flat = output.view(-1, ntokens)\n",
    "            total_loss += len(data) * criterion(output_flat, targets).item()\n",
    "    return total_loss / (len(data_source) - 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Ig2E8iahakDW"
   },
   "outputs": [],
   "source": [
    "val_x\n",
    "test_x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "e97a6U0pzuit"
   },
   "outputs": [],
   "source": [
    "best_val_loss = float(\"inf\")\n",
    "epochs = 3 # The number of epochs\n",
    "best_model = None\n",
    "\n",
    "for epoch in range(1, epochs + 1):\n",
    "    epoch_start_time = time.time()\n",
    "    train()\n",
    "    val_loss = evaluate(model, val_x)\n",
    "    print('-' * 89)\n",
    "    print('| end of epoch {:3d} | time: {:5.2f}s | valid loss {:5.2f} | '\n",
    "          'valid ppl {:8.2f}'.format(epoch, (time.time() - epoch_start_time),\n",
    "                                     val_loss, math.exp(val_loss)))\n",
    "    print('-' * 89)\n",
    "\n",
    "    if val_loss < best_val_loss:\n",
    "        best_val_loss = val_loss\n",
    "        best_model = model\n",
    "\n",
    "    scheduler.step()"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "lstm+128+위치만.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
