{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Trajectory 사람 이동 예측\n",
    "trajectory 데이터에서 총 180명 정도의 데이터가 존재 <br>\n",
    "데이터 출처 : https://www.microsoft.com/en-us/download/details.aspx?id=52367&from=http%3A%2F%2Fresearch.microsoft.com%2Fen-us%2Fdownloads%2Fb16d359d-d164-469e-9fd4-daa38f2b2e13%2F<br>\n",
    "개인 별로 어떻게 움직일지를 lstm, gru (파라미터가 좀 작을 때 사용하는 모델),transfomer 모형을 활용해서 학습해볼 예정 <br>\n",
    "## 표본 선정 기준<br>\n",
    "1. 수집 일 수가 많을 것 <br>\n",
    "2. 일정하게 데이터가 존재할 것 <br>\n",
    "결과적으로 총 6명을 학습 할 예정이다. <br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "list_ = os.listdir('sorted_data/128/Trajectory/')\n",
    "sorted_41 = []\n",
    "for i in range(len(list_)):\n",
    "    file_ = open('sorted_data/128/Trajectory/' + list_[i], 'r') \n",
    "    file = file_.readlines()\n",
    "    file = file[6:]\n",
    "    for j in range(len(file)):\n",
    "        tmp = file[j].split(',')\n",
    "        sorted_41.append([float(tmp[0]), float(tmp[1]), tmp[-2] + ' ' +tmp[-1][:-1]])\n",
    "\n",
    "df = pd.DataFrame(sorted_41)\n",
    "df[2] = pd.to_datetime(df[2])\n",
    "df.sort_values(by = [2],inplace=True)\n",
    "df = df.reset_index()\n",
    "df = df[[0,1,2]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1208500"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 데이터 분리하기\n",
    "1. 데이터가 너무 많다는 점\n",
    "2. 어느 곳에 방문할지에 대한 정보가 좀 더 중요하다는 점\n",
    "3. 사람이 걸을 수 있는 정도가 한정되어 있다는 점 <br>\n",
    "세가지를 고려할 때 모두를 학습시키기 보다는 일부분을 쪼개서 학습시키는 것이 합리적"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = []\n",
    "for i in range(1208499):\n",
    "    if i % 30 == 0:\n",
    "        diff = df[2].iloc[i + 1] - df[2].iloc[i]\n",
    "        a.append(diff)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "result = a[0]\n",
    "for i in range(1,len(a)):\n",
    "    result += a[i]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Timedelta('0 days 00:01:27.645094826')"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result / len(a)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 30분 단위로 쪼개서 이 사람의 미래 예측하는 형태\n",
    "    평균이 1분 27초 정도되니 30정도 곱해서 30분 단위로 예측해볼 것임"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_diff_30 = []\n",
    "for i in range(0,len(df),30):\n",
    "    df_diff_30.append(df.iloc[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "40284"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(df_diff_30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_diff_30_pd = pd.DataFrame(df_diff_30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0          40.075850\n",
       " 30         40.076483\n",
       " 60         40.051017\n",
       " 90         40.046900\n",
       " 120        40.040267\n",
       "              ...    \n",
       " 1208370    39.987238\n",
       " 1208400    39.986165\n",
       " 1208430    39.985208\n",
       " 1208460    39.979902\n",
       " 1208490    39.976603\n",
       " Name: 0, Length: 40284, dtype: float64,\n",
       " 0          116.327817\n",
       " 30         116.321833\n",
       " 60         116.323883\n",
       " 90         116.320683\n",
       " 120        116.325833\n",
       "               ...    \n",
       " 1208370    116.402507\n",
       " 1208400    116.364760\n",
       " 1208430    116.330910\n",
       " 1208460    116.327333\n",
       " 1208490    116.331755\n",
       " Name: 1, Length: 40284, dtype: float64,\n",
       " 0         2007-04-14 00:56:28\n",
       " 30        2007-04-14 01:10:40\n",
       " 60        2007-04-14 01:35:35\n",
       " 90        2007-04-14 01:48:46\n",
       " 120       2007-04-14 01:59:23\n",
       "                   ...        \n",
       " 1208370   2011-03-10 07:48:47\n",
       " 1208400   2011-03-10 07:51:51\n",
       " 1208430   2011-03-10 07:54:49\n",
       " 1208460   2011-03-10 07:57:23\n",
       " 1208490   2011-03-10 07:59:42\n",
       " Name: 2, Length: 40284, dtype: datetime64[ns])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_diff_30_pd[0], df_diff_30_pd[1], df_diff_30_pd[2]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 30분 단위로 쪼갠다!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_128_30 = pd.DataFrame(df_diff_30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "x, y = df_128_30[0], df_128_30[1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 모델 학습 데이터 준비\n",
    "    x, y 차원을 맞추는 것이 어려운 점이었음\n",
    "    gru 모델 2개를 활용해서 한 차원 당 1개의 모델을 사용하도록 하였음.\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "ename": "OSError",
     "evalue": "[WinError 1455] 이 작업을 완료하기 위한 페이징 파일이 너무 작습니다. Error loading \"C:\\Users\\SungJin\\anaconda3\\lib\\site-packages\\torch\\lib\\caffe2_detectron_ops_gpu.dll\" or one of its dependencies.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mOSError\u001b[0m                                   Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-12-728e48c417c9>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mrandom\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mnumpy\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m \u001b[1;32mimport\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      4\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;31m# multivariate data preparation\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\torch\\__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m    114\u001b[0m                 \u001b[0merr\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mctypes\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mWinError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlast_error\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    115\u001b[0m                 \u001b[0merr\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstrerror\u001b[0m \u001b[1;33m+=\u001b[0m \u001b[1;34m' Error loading \"{}\" or one of its dependencies.'\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdll\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 116\u001b[1;33m                 \u001b[1;32mraise\u001b[0m \u001b[0merr\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    117\u001b[0m             \u001b[1;32melif\u001b[0m \u001b[0mres\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    118\u001b[0m                 \u001b[0mis_loaded\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mOSError\u001b[0m: [WinError 1455] 이 작업을 완료하기 위한 페이징 파일이 너무 작습니다. Error loading \"C:\\Users\\SungJin\\anaconda3\\lib\\site-packages\\torch\\lib\\caffe2_detectron_ops_gpu.dll\" or one of its dependencies."
     ]
    }
   ],
   "source": [
    "import random\n",
    "import numpy as np\n",
    "import torch\n",
    "\n",
    "# multivariate data preparation\n",
    "from numpy import array\n",
    "from numpy import hstack\n",
    " \n",
    "# split a multivariate sequence into samples\n",
    "def split_sequences(sequences, n_steps):\n",
    "    X, y = list(), list()\n",
    "    for i in range(len(sequences)-n_steps):\n",
    "        # find the end of this pattern\n",
    "        end_ix = i + n_steps\n",
    "        # check if we are beyond the dataset\n",
    "        if end_ix > len(sequences):\n",
    "            break\n",
    "        # gather input and output parts of the pattern\n",
    "        seq_x, seq_y = sequences[i:end_ix, :-2], sequences[end_ix, -2:]\n",
    "        X.append(seq_x)\n",
    "        y.append(seq_y)\n",
    "    return array(X), array(y)\n",
    " \n",
    "# x, y\n",
    "# define input sequence\n",
    "in_seq1 = x.values\n",
    "in_seq2 = y.values\n",
    "# convert to [rows, columns] structure\n",
    "in_seq1 = in_seq1.reshape((len(in_seq1), 1))\n",
    "in_seq2 = in_seq2.reshape((len(in_seq2), 1))\n",
    "#out_seq = out_seq.reshape((len(out_seq), 1))\n",
    "# horizontally stack columns\n",
    "dataset = hstack((in_seq1, in_seq2, in_seq1, in_seq2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = split_sequences(dataset, 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# GRU 모델 학습"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MV_LSTM(torch.nn.Module):\n",
    "    def __init__(self,n_features,seq_length):\n",
    "        super(MV_LSTM, self).__init__()\n",
    "        self.n_features = n_features\n",
    "        self.seq_len = seq_length\n",
    "        self.n_hidden = 50 # number of hidden states\n",
    "        self.n_layers = 10 # number of LSTM layers (stacked)\n",
    "    \n",
    "        self.l_lstm = torch.nn.GRU(input_size = n_features, \n",
    "                                 hidden_size = self.n_hidden,\n",
    "                                 num_layers = self.n_layers, \n",
    "                                 batch_first = True)\n",
    "        # according to pytorch docs LSTM output is \n",
    "        # (batch_size,seq_len, num_directions * hidden_size)\n",
    "        # when considering batch_first = True\n",
    "        self.l_linear = torch.nn.Linear(self.n_hidden*self.seq_len, 1)\n",
    "        \n",
    "    \n",
    "    def init_hidden(self, batch_size):\n",
    "        # even with batch_first = True this remains same as docs\n",
    "        hidden_state = torch.zeros(self.n_layers,batch_size,self.n_hidden)\n",
    "        cell_state = torch.zeros(self.n_layers,batch_size,self.n_hidden)\n",
    "        self.hidden = (hidden_state, cell_state)\n",
    "    \n",
    "    \n",
    "    def forward(self, x):\n",
    "        batch_size, seq_len, _ = x.size()\n",
    "        \n",
    "        lstm_out, self.hidden = self.l_lstm(x, self.hidden)\n",
    "        # lstm_out(with batch_first = True) is \n",
    "        # (batch_size,seq_len,num_directions * hidden_size)\n",
    "        # for following linear layer we want to keep batch_size dimension and merge rest       \n",
    "        # .contiguous() -> solves tensor compatibility error\n",
    "        x = lstm_out.contiguous().view(batch_size,-1)\n",
    "        return self.l_linear(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(40279, 5, 2) (40279, 2)\n"
     ]
    }
   ],
   "source": [
    "n_features = 1 # this is number of parallel inputs\n",
    "n_timesteps = 5 # this is number of timesteps\n",
    "\n",
    "# convert dataset into input/output\n",
    "X, y = split_sequences(dataset, n_timesteps)\n",
    "print(X.shape, y.shape)\n",
    "\n",
    "# create NN\n",
    "mv_net_x = MV_LSTM(n_features, n_timesteps)\n",
    "mv_net_y = MV_LSTM(n_features, n_timesteps)\n",
    "criterion = torch.nn.MSELoss() # reduction='sum' created huge loss value\n",
    "optimizer_x = torch.optim.Adam(mv_net_x.parameters(), lr=1e-1)\n",
    "optimizer_y = torch.optim.Adam(mv_net_y.parameters(), lr=1e-1)\n",
    "\n",
    "train_episodes = 500\n",
    "batch_size = 20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "numpy.ndarray"
      ]
     },
     "execution_count": 132,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(X) \n",
    "# 여기서 타입 에러가 발생했음 # float 타입으로 결과를 만들어야 했는데\n",
    "# 위에서 string 타입으로 데이터 프레임을 만들어내서 문제가 발생"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[ 40.07585   , 116.32781667],\n",
       "        [ 40.07648333, 116.32183333],\n",
       "        [ 40.05101667, 116.32388333],\n",
       "        [ 40.0469    , 116.32068333],\n",
       "        [ 40.04026667, 116.32583333]],\n",
       "\n",
       "       [[ 40.07648333, 116.32183333],\n",
       "        [ 40.05101667, 116.32388333],\n",
       "        [ 40.0469    , 116.32068333],\n",
       "        [ 40.04026667, 116.32583333],\n",
       "        [ 40.03626667, 116.31031667]],\n",
       "\n",
       "       [[ 40.05101667, 116.32388333],\n",
       "        [ 40.0469    , 116.32068333],\n",
       "        [ 40.04026667, 116.32583333],\n",
       "        [ 40.03626667, 116.31031667],\n",
       "        [ 40.01473333, 116.31171667]],\n",
       "\n",
       "       ...,\n",
       "\n",
       "       [[ 39.9705499 , 116.4605233 ],\n",
       "        [ 39.9647216 , 116.464055  ],\n",
       "        [ 39.98799   , 116.4282633 ],\n",
       "        [ 39.9872383 , 116.4025066 ],\n",
       "        [ 39.986165  , 116.3647599 ]],\n",
       "\n",
       "       [[ 39.9647216 , 116.464055  ],\n",
       "        [ 39.98799   , 116.4282633 ],\n",
       "        [ 39.9872383 , 116.4025066 ],\n",
       "        [ 39.986165  , 116.3647599 ],\n",
       "        [ 39.9852083 , 116.3309099 ]],\n",
       "\n",
       "       [[ 39.98799   , 116.4282633 ],\n",
       "        [ 39.9872383 , 116.4025066 ],\n",
       "        [ 39.986165  , 116.3647599 ],\n",
       "        [ 39.9852083 , 116.3309099 ],\n",
       "        [ 39.9799016 , 116.3273333 ]]])"
      ]
     },
     "execution_count": 133,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 여기서도 어려웠던 점\n",
    "    인풋 사이즈를 맞춰줘야 하는데 그 자체가 코드를 모두 이해하여야 했기에 엄청난 어려움이 있었다.\n",
    "    ★시계열 데이터이기 때문에 마지막 배치의 경우에 문제가 존재했음 -> 이 부분을 처리하는 것이 중요!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 40.03626667, 116.31031667],\n",
       "       [ 40.01473333, 116.31171667],\n",
       "       [ 39.99198333, 116.30961667],\n",
       "       ...,\n",
       "       [ 39.9852083 , 116.3309099 ],\n",
       "       [ 39.9799016 , 116.3273333 ],\n",
       "       [ 39.9766033 , 116.3317549 ]])"
      ]
     },
     "execution_count": 142,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(40279, 2)"
      ]
     },
     "execution_count": 145,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step :  0 loss :  245.24386596679688\n",
      "step :  1 loss :  232.52220153808594\n",
      "step :  2 loss :  229.64219665527344\n",
      "step :  3 loss :  228.66375732421875\n",
      "step :  4 loss :  228.3067169189453\n",
      "step :  5 loss :  228.17318725585938\n",
      "step :  6 loss :  228.28575134277344\n",
      "step :  7 loss :  228.1910858154297\n",
      "step :  8 loss :  228.129638671875\n",
      "step :  9 loss :  228.1063232421875\n",
      "step :  10 loss :  228.09756469726562\n",
      "step :  11 loss :  228.09390258789062\n",
      "step :  12 loss :  228.09263610839844\n",
      "step :  13 loss :  228.09226989746094\n",
      "step :  14 loss :  228.09222412109375\n",
      "step :  15 loss :  228.09222412109375\n",
      "step :  16 loss :  228.09207153320312\n",
      "step :  17 loss :  228.0917510986328\n",
      "step :  18 loss :  228.09226989746094\n",
      "step :  19 loss :  228.09207153320312\n",
      "step :  20 loss :  228.0921630859375\n",
      "step :  21 loss :  228.09194946289062\n",
      "step :  22 loss :  228.09207153320312\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-171-45dcfb5a33ee>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     34\u001b[0m             \u001b[0mloss\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     35\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 36\u001b[1;33m             \u001b[0moptimizer_x\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     37\u001b[0m             \u001b[0moptimizer_x\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;31m# x가 0으로 흐르도록 함\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     38\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\torch\\autograd\\grad_mode.py\u001b[0m in \u001b[0;36mdecorate_context\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     13\u001b[0m         \u001b[1;32mdef\u001b[0m \u001b[0mdecorate_context\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     14\u001b[0m             \u001b[1;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 15\u001b[1;33m                 \u001b[1;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     16\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mdecorate_context\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     17\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\torch\\optim\\adam.py\u001b[0m in \u001b[0;36mstep\u001b[1;34m(self, closure)\u001b[0m\n\u001b[0;32m     97\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     98\u001b[0m                 \u001b[1;31m# Decay the first and second moment running average coefficient\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 99\u001b[1;33m                 \u001b[0mexp_avg\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmul_\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbeta1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0madd_\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mgrad\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0malpha\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1\u001b[0m \u001b[1;33m-\u001b[0m \u001b[0mbeta1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    100\u001b[0m                 \u001b[0mexp_avg_sq\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmul_\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbeta2\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0maddcmul_\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mgrad\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mgrad\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1\u001b[0m \u001b[1;33m-\u001b[0m \u001b[0mbeta2\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    101\u001b[0m                 \u001b[1;32mif\u001b[0m \u001b[0mamsgrad\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "mv_net_x.train()\n",
    "mv_net_y.train()\n",
    "\n",
    "for t in range(train_episodes):\n",
    "    for b in range(0,len(X),batch_size):\n",
    "        inpt = X[b:b+batch_size,:,:]\n",
    "        target = y[b:b+batch_size]\n",
    "\n",
    "        # x, y 트레인셋\n",
    "        x_batch = torch.tensor(inpt[:,:,0],dtype=torch.float32)\n",
    "        y_batch = torch.tensor(inpt[:,:,1],dtype=torch.float32)\n",
    "\n",
    "        if x_batch.shape == (batch_size,n_timesteps):\n",
    "            x_batch = x_batch.reshape(batch_size,n_timesteps,1) # 3 채널로 맞춰줘야 함\n",
    "            y_batch = y_batch.reshape(batch_size,n_timesteps,1)\n",
    "\n",
    "            mv_net_x.init_hidden(x_batch.size(0))\n",
    "            mv_net_y.init_hidden(y_batch.size(0))\n",
    "\n",
    "            # x,y의 예측 값\n",
    "            output_x = mv_net_x(x_batch)\n",
    "            output_y = mv_net_y(y_batch)\n",
    "\n",
    "            # x,y의 정답\n",
    "            target_x_batch = torch.tensor(target[:, 0],dtype=torch.float32)\n",
    "            target_y_batch = torch.tensor(target[:, 1],dtype=torch.float32)\n",
    "\n",
    "\n",
    "        #    lstm_out, _ = mv_net.l_lstm(x_batch,nnet.hidden)    \n",
    "        #    lstm_out.contiguous().view(x_batch.size(0),-1)\n",
    "\n",
    "            # loss function이 두개의 합이 최소가 되는 쪽으로 loss를 구함\n",
    "            loss = criterion(output_x.view(-1), target_x_batch) + criterion(output_y.view(-1), target_y_batch)\n",
    "            loss.backward()\n",
    "\n",
    "            optimizer_x.step()        \n",
    "            optimizer_x.zero_grad() # x가 0으로 흐르도록 함\n",
    "\n",
    "            optimizer_y.step()\n",
    "            optimizer_y.zero_grad() # y가 0으로 흐르도록 함\n",
    "    print('step : ' , t , 'loss : ' , loss.item())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
